{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7858458,"sourceType":"datasetVersion","datasetId":4609518}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/mitriya/phishing-url-detection?scriptVersionId=167360668\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-16T19:49:59.651436Z","iopub.execute_input":"2024-03-16T19:49:59.651918Z","iopub.status.idle":"2024-03-16T19:50:00.13217Z","shell.execute_reply.started":"2024-03-16T19:49:59.651886Z","shell.execute_reply":"2024-03-16T19:50:00.130362Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"/kaggle/input/phishing-dataset/final_data.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# # Load the dataset\n# data1 = pd.read_csv(\"/kaggle/input/phishing-emails/Enron.csv\")\n# print(len(data1))\n# data1.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-16T19:50:18.116352Z","iopub.execute_input":"2024-03-16T19:50:18.116715Z","iopub.status.idle":"2024-03-16T19:50:18.123599Z","shell.execute_reply.started":"2024-03-16T19:50:18.116687Z","shell.execute_reply":"2024-03-16T19:50:18.121949Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# data2 = pd.read_csv(\"/kaggle/input/phishing-emails/Ling.csv\")\n# print(len(data2))\n# data2.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-16T19:50:23.08903Z","iopub.execute_input":"2024-03-16T19:50:23.089474Z","iopub.status.idle":"2024-03-16T19:50:23.094361Z","shell.execute_reply.started":"2024-03-16T19:50:23.089444Z","shell.execute_reply":"2024-03-16T19:50:23.09332Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# data3 = pd.read_csv(\"/kaggle/input/phishing-emails/SpamAssasin.csv\")\n# data3.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-16T19:50:27.194333Z","iopub.execute_input":"2024-03-16T19:50:27.195776Z","iopub.status.idle":"2024-03-16T19:50:27.201578Z","shell.execute_reply.started":"2024-03-16T19:50:27.195512Z","shell.execute_reply":"2024-03-16T19:50:27.199959Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# data4 = data3.drop(columns=[\"sender\",\"receiver\",\"date\",\"urls\"])\n# print(len(data4))\n# data4.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-16T19:50:31.421838Z","iopub.execute_input":"2024-03-16T19:50:31.42234Z","iopub.status.idle":"2024-03-16T19:50:31.427324Z","shell.execute_reply.started":"2024-03-16T19:50:31.422306Z","shell.execute_reply":"2024-03-16T19:50:31.426298Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# data5 = pd.read_csv(\"/kaggle/input/phishing-emails-2/TREC_05.csv\")\n# print(len(data5))\n# data5.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-16T19:50:34.178915Z","iopub.execute_input":"2024-03-16T19:50:34.179942Z","iopub.status.idle":"2024-03-16T19:50:34.184506Z","shell.execute_reply.started":"2024-03-16T19:50:34.179906Z","shell.execute_reply":"2024-03-16T19:50:34.183288Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# data6 = pd.read_csv(\"/kaggle/input/fishing-mail/Phishing_Email.csv\")\n# print(len(data6))\n# data6.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-16T19:50:34.752908Z","iopub.execute_input":"2024-03-16T19:50:34.753323Z","iopub.status.idle":"2024-03-16T19:50:34.759485Z","shell.execute_reply.started":"2024-03-16T19:50:34.753292Z","shell.execute_reply":"2024-03-16T19:50:34.758041Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# data7 = pd.read_csv(\"/kaggle/input/phishing-emails/phishing_templates_gpt1.csv\")\n# print(len(data7))\n# data7.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-16T19:50:35.318809Z","iopub.execute_input":"2024-03-16T19:50:35.319206Z","iopub.status.idle":"2024-03-16T19:50:35.324776Z","shell.execute_reply.started":"2024-03-16T19:50:35.319178Z","shell.execute_reply":"2024-03-16T19:50:35.323564Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# combined_data = pd.concat([data1,data2,data4])\n# print(len(combined_data))\n# combined_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-16T19:50:56.090249Z","iopub.execute_input":"2024-03-16T19:50:56.091199Z","iopub.status.idle":"2024-03-16T19:50:56.096303Z","shell.execute_reply.started":"2024-03-16T19:50:56.091163Z","shell.execute_reply":"2024-03-16T19:50:56.095326Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import re\n\nregex = r\"\\b((?:https?://)?(?:(?:www\\.)?(?:[\\da-z\\.-]+)\\.(?:[a-z]{2,6})|(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)|(?:(?:[0-9a-fA-F]{1,4}:){7,7}[0-9a-fA-F]{1,4}|(?:[0-9a-fA-F]{1,4}:){1,7}:|(?:[0-9a-fA-F]{1,4}:){1,6}:[0-9a-fA-F]{1,4}|(?:[0-9a-fA-F]{1,4}:){1,5}(?::[0-9a-fA-F]{1,4}){1,2}|(?:[0-9a-fA-F]{1,4}:){1,4}(?::[0-9a-fA-F]{1,4}){1,3}|(?:[0-9a-fA-F]{1,4}:){1,3}(?::[0-9a-fA-F]{1,4}){1,4}|(?:[0-9a-fA-F]{1,4}:){1,2}(?::[0-9a-fA-F]{1,4}){1,5}|[0-9a-fA-F]{1,4}:(?:(?::[0-9a-fA-F]{1,4}){1,6})|:(?:(?::[0-9a-fA-F]{1,4}){1,7}|:)|fe80:(?::[0-9a-fA-F]{0,4}){0,4}%[0-9a-zA-Z]{1,}|::(?:ffff(?::0{1,4}){0,1}:){0,1}(?:(?:25[0-5]|(?:2[0-4]|1{0,1}[0-9]){0,1}[0-9])\\.){3,3}(?:25[0-5]|(?:2[0-4]|1{0,1}[0-9]){0,1}[0-9])|(?:[0-9a-fA-F]{1,4}:){1,4}:(?:(?:25[0-5]|(?:2[0-4]|1{0,1}[0-9]){0,1}[0-9])\\.){3,3}(?:25[0-5]|(?:2[0-4]|1{0,1}[0-9]){0,1}[0-9])))(?::[0-9]{1,4}|[1-5][0-9]{4}|6[0-4][0-9]{3}|65[0-4][0-9]{2}|655[0-2][0-9]|6553[0-5])?(?:/[\\w\\.-]*)*/?)\\b\"","metadata":{"execution":{"iopub.status.busy":"2024-03-16T19:51:04.530402Z","iopub.execute_input":"2024-03-16T19:51:04.531164Z","iopub.status.idle":"2024-03-16T19:51:04.536821Z","shell.execute_reply.started":"2024-03-16T19:51:04.531098Z","shell.execute_reply":"2024-03-16T19:51:04.535504Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# # Create a function to check for the presence of a URL in body of each row of data\n# def check_for_url(row):\n#     if re.search(regex, str(row['body'])):\n#         # Extract the URL from the body of the row\n#         return re.search(regex, str(row['body'])).group()\n#     else:\n#         return 'No URL found'\n\n# # Extract the URL from the body of each row of data and store it in a new column\n# combined_data['url'] = combined_data.apply(check_for_url, axis=1)\n\n# # Filter the dataframe with only rows that have a URL in the body\n# filtered_data = combined_data[combined_data['url'] != 'No URL found']\n\n# filtered_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-16T19:51:17.169698Z","iopub.execute_input":"2024-03-16T19:51:17.17039Z","iopub.status.idle":"2024-03-16T19:51:17.175145Z","shell.execute_reply.started":"2024-03-16T19:51:17.170357Z","shell.execute_reply":"2024-03-16T19:51:17.174076Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Load the dataset\nfiltered_data = pd.read_csv(\"/kaggle/input/phishing-dataset/final_data.csv\")\nprint(len(filtered_data))\nfiltered_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-16T19:51:19.272776Z","iopub.execute_input":"2024-03-16T19:51:19.273273Z","iopub.status.idle":"2024-03-16T19:51:19.595416Z","shell.execute_reply.started":"2024-03-16T19:51:19.273238Z","shell.execute_reply":"2024-03-16T19:51:19.593828Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"4944\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"                                          subject  \\\n0                        Re: New Sequences Window   \n1                       [zzzzteana] RE: Alexander   \n2                       [zzzzteana] Moscow bomber   \n3           [IRR] Klez: The Virus That  Won't Die   \n4  Re: [zzzzteana] Nothing like mama used to make   \n\n                                                body  label  \\\n0  Date:        Wed, 21 Aug 2002 10:54:46 -0500  ...      0   \n1  Martin A posted:\\nTassos Papadopoulos, the Gre...      0   \n2  Man Threatens Explosion In Moscow \\n\\nThursday...      0   \n3  Klez: The Virus That Won't Die\\n \\nAlready the...      0   \n4  >  in adding cream to spaghetti carbonara, whi...      0   \n\n                                                 url  \n0                                deepeddy.vircio.com  \n1  http://us.click.yahoo.com/pt6YBB/NXiEAA/mG3HAA...  \n2  http://us.click.yahoo.com/pt6YBB/NXiEAA/mG3HAA...  \n3              http://www.pcworld.com/news/article/0  \n4                             http://www.ee.ed.ac.uk  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject</th>\n      <th>body</th>\n      <th>label</th>\n      <th>url</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Re: New Sequences Window</td>\n      <td>Date:        Wed, 21 Aug 2002 10:54:46 -0500  ...</td>\n      <td>0</td>\n      <td>deepeddy.vircio.com</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[zzzzteana] RE: Alexander</td>\n      <td>Martin A posted:\\nTassos Papadopoulos, the Gre...</td>\n      <td>0</td>\n      <td>http://us.click.yahoo.com/pt6YBB/NXiEAA/mG3HAA...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[zzzzteana] Moscow bomber</td>\n      <td>Man Threatens Explosion In Moscow \\n\\nThursday...</td>\n      <td>0</td>\n      <td>http://us.click.yahoo.com/pt6YBB/NXiEAA/mG3HAA...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[IRR] Klez: The Virus That  Won't Die</td>\n      <td>Klez: The Virus That Won't Die\\n \\nAlready the...</td>\n      <td>0</td>\n      <td>http://www.pcworld.com/news/article/0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Re: [zzzzteana] Nothing like mama used to make</td>\n      <td>&gt;  in adding cream to spaghetti carbonara, whi...</td>\n      <td>0</td>\n      <td>http://www.ee.ed.ac.uk</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# **URL Features**","metadata":{}},{"cell_type":"code","source":"# This file contains all the feature extraction functions.\n# Each function extracts a particular feature from URL\n\nimport re\nfrom urllib.parse import *","metadata":{"execution":{"iopub.status.busy":"2024-03-16T19:51:23.882783Z","iopub.execute_input":"2024-03-16T19:51:23.883206Z","iopub.status.idle":"2024-03-16T19:51:23.887865Z","shell.execute_reply.started":"2024-03-16T19:51:23.883172Z","shell.execute_reply":"2024-03-16T19:51:23.886793Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Embedded Domain: Examines dot-separated domain/hostname patterns in the URL path.\n\ndef embedded_domain(url):\n    # Extract the domain from the URL\n    domain = urlparse(url).netloc\n    # Split the domain into its components\n    domain_parts = domain.split('.')\n    \n    # Checking whether the url is similar to a well-known domain\n    # If it is, we return 1, else 0\n    well_known_URLs = ['google', 'facebook', 'twitter', 'linkedin', 'youtube', 'instagram', 'pinterest', 'amazon', 'snapchat', 'reddit', 'flickr', 'whatsapp', 'quora', 'vimeo', 'periscope', 'vine', 'meetup', 'tagged', 'askfm', 'meetme', 'meetup', 'myspace', 'stumbleupon', 'delicious', 'digg', 'slashdot', 'fark', 'newsvine', 'foursquare', 'yelp', 'tripadvisor', 'zomato', 'opentable']\n    \n    for well_known_URL in well_known_URLs:\n        for domain_part in domain_parts:\n            if len(set(domain_part)&set(well_known_URL)) == len(well_known_URL) - 1:\n                return 1\n    return -1\n\n\n# Example usage\nurl1 = \"http://www.google.com\"\nurl2 = \"http://www.facehook.com\"\n\nprint(embedded_domain(url1))\nprint(embedded_domain(url2))","metadata":{"execution":{"iopub.status.busy":"2024-03-16T19:51:26.312755Z","iopub.execute_input":"2024-03-16T19:51:26.313183Z","iopub.status.idle":"2024-03-16T19:51:26.325509Z","shell.execute_reply.started":"2024-03-16T19:51:26.313152Z","shell.execute_reply":"2024-03-16T19:51:26.32415Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"-1\n1\n","output_type":"stream"}]},{"cell_type":"code","source":"# IP Address: Attackers often employ IP address in the URL\n# to disguise a webpage’s malicious nature, while legitimate\n# websites almost always use domain names instead of IP\n# addresses due to their easy memorability.\n\ndef having_ip_address(url):\n    # Regular expression to match IP address pattern\n    ip_address_pattern = r'\\b\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\b'\n\n    # Search for the pattern in the URL\n    match = re.search(ip_address_pattern, url)\n\n    if match:\n        # print match.group()\n        return -1\n    else:\n        # print 'No matching pattern found'\n        return 1\n    \n# Example usage\nurl1 = \"https://www.google.com\"\nurl2 = \"172.0.0.1\"\n\nprint(having_ip_address(url1))\nprint(having_ip_address(url2))","metadata":{"execution":{"iopub.status.busy":"2024-03-16T19:51:29.39642Z","iopub.execute_input":"2024-03-16T19:51:29.396778Z","iopub.status.idle":"2024-03-16T19:51:29.407297Z","shell.execute_reply.started":"2024-03-16T19:51:29.39675Z","shell.execute_reply":"2024-03-16T19:51:29.405591Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"1\n-1\n","output_type":"stream"}]},{"cell_type":"code","source":"# Number of dots in URL: Phishing pages tend to use more\n# dots in their URLs than the legitimate sites.\ndef no_of_dots(url):\n    return url.count('.')\n\n# Example usage\nurl = \"https://www.google.com\"\n\nprint(no_of_dots(url))","metadata":{"execution":{"iopub.status.busy":"2024-03-16T19:51:30.935287Z","iopub.execute_input":"2024-03-16T19:51:30.935754Z","iopub.status.idle":"2024-03-16T19:51:30.943679Z","shell.execute_reply.started":"2024-03-16T19:51:30.93572Z","shell.execute_reply":"2024-03-16T19:51:30.942244Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"2\n","output_type":"stream"}]},{"cell_type":"code","source":"# Lexical features: The URL string is broken down into\n# multiple tokens. Each token constitutes a binary feature.\n# The delimiters to obtain the tokens are ‘/’, ‘?’, ‘.’, ‘=’, ‘ ’,\n# ‘&’, and ‘-’\n\ndef extract_lexical_features(url):\n    # Parse the URL\n    parsed_url = urlparse(url)\n\n    # Define delimiters\n    delimiters = ['/', '?', '.', '=', ' ', '&', '-']\n\n    # Split the url into tokens based on the delimiters\n    tokens = re.split('|'.join(map(re.escape, delimiters)), parsed_url.geturl())\n\n    # Remove empty tokens\n    tokens = list(filter(None, tokens))\n\n    # Initialize a dictionary to store binary features for each token\n    lexical_features = {}\n\n    # Extract binary features for each token\n    for token in tokens:\n        lexical_features[token] = 1\n    \n    return lexical_features\n\n# Example usage\n\nurl = 'https://www.google.com/search?q=feature+extraction+from+url&oq=feature+extraction+from+url&aqs=chrome..69i57j0l7.10257j0j7&sourceid=chrome&ie=UTF-8'\n\nprint(extract_lexical_features(url))","metadata":{"execution":{"iopub.status.busy":"2024-03-16T19:51:32.617175Z","iopub.execute_input":"2024-03-16T19:51:32.617539Z","iopub.status.idle":"2024-03-16T19:51:32.627079Z","shell.execute_reply.started":"2024-03-16T19:51:32.617512Z","shell.execute_reply":"2024-03-16T19:51:32.625638Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"{'https:': 1, 'www': 1, 'google': 1, 'com': 1, 'search': 1, 'q': 1, 'feature+extraction+from+url': 1, 'oq': 1, 'aqs': 1, 'chrome': 1, '69i57j0l7': 1, '10257j0j7': 1, 'sourceid': 1, 'ie': 1, 'UTF': 1, '8': 1}\n","output_type":"stream"}]},{"cell_type":"code","source":"# Number of sensitive words in URL: In (Garera et al., 2007),\n# Garera et al summarized a set of eight sensitive words that\n# frequently appear in phishing URLs. This is a numeric feature with a range of 0 to 8.\n\ndef no_of_sensitive_words(url):\n    sensitive_words = ['confirm', 'account', 'banking', 'secure', 'ebayisapi', 'webscr', 'login', 'signin']\n    count = 0\n    for word in sensitive_words:\n        if word in url:\n            count += 1\n    return count\n\n# Example usage\nurl1 = \"https://www.google.com\"\nurl2 = \"http://www.abc.com/confirm\"\n\nprint(no_of_sensitive_words(url1))\nprint(no_of_sensitive_words(url2))","metadata":{"execution":{"iopub.status.busy":"2024-03-16T19:51:34.370594Z","iopub.execute_input":"2024-03-16T19:51:34.370947Z","iopub.status.idle":"2024-03-16T19:51:34.37896Z","shell.execute_reply.started":"2024-03-16T19:51:34.37092Z","shell.execute_reply":"2024-03-16T19:51:34.377634Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"0\n1\n","output_type":"stream"}]},{"cell_type":"code","source":"# Out-of-Position Top Level Domain (TLD): Checks for\n# unusual positioning of TLDs in the URL.\n\ndef out_of_position_tld(url):\n    tld = ['com', 'org', 'net', 'edu', 'gov', 'in']\n    \n    domain = urlparse(url).netloc\n    # check if the TLD is in the middle of the domain\n    tokens = domain.split('.')\n    for i in range(len(tokens) - 1):\n        if tokens[i] in tld:\n            return -1\n    return 1\n\n# Example usage\nurl1 = 'http://www.google.com'\nurl2 = 'http://www.google.com.in'\n    \nprint(out_of_position_tld(url1))\nprint(out_of_position_tld(url2))","metadata":{"execution":{"iopub.status.busy":"2024-03-16T19:51:38.294262Z","iopub.execute_input":"2024-03-16T19:51:38.29464Z","iopub.status.idle":"2024-03-16T19:51:38.304979Z","shell.execute_reply.started":"2024-03-16T19:51:38.29461Z","shell.execute_reply":"2024-03-16T19:51:38.303417Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"1\n-1\n","output_type":"stream"}]},{"cell_type":"code","source":"# Check if the website is using HTTPS\ndef https_token(url):\n    https_tokens = url.split('//')[0]\n    if https_tokens == 'https:':\n        return 1\n    else:\n        return -1\n\n# Example usage\nurl1 = 'http://www.google.com'\nurl2 = 'https://www.google.com'\n\nprint(https_token(url1))\nprint(https_token(url2))","metadata":{"execution":{"iopub.status.busy":"2024-03-16T19:51:40.614307Z","iopub.execute_input":"2024-03-16T19:51:40.614668Z","iopub.status.idle":"2024-03-16T19:51:40.622229Z","shell.execute_reply.started":"2024-03-16T19:51:40.614642Z","shell.execute_reply":"2024-03-16T19:51:40.620976Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"-1\n1\n","output_type":"stream"}]},{"cell_type":"code","source":"# Get the length of the URL\ndef url_length(url):\n    return len(url)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T19:51:48.822837Z","iopub.execute_input":"2024-03-16T19:51:48.823424Z","iopub.status.idle":"2024-03-16T19:51:48.832755Z","shell.execute_reply.started":"2024-03-16T19:51:48.823361Z","shell.execute_reply":"2024-03-16T19:51:48.831346Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# If the URL is using Shortening Services, the value assigned to this feature is 1 (phishing) or else -1 (legitimate).\n\n# listing shortening services\nshortening_services = r\"bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|\" \\\n                      r\"yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|\" \\\n                      r\"short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|\" \\\n                      r\"doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|db\\.tt|\" \\\n                      r\"qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|q\\.gs|is\\.gd|\" \\\n                      r\"po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|x\\.co|\" \\\n                      r\"prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|\" \\\n                      r\"tr\\.im|link\\.zip\\.net\"\n\n# Checking for Shortening Services in URL (Tiny_URL)\ndef tinyURL(url):\n    match=re.search(shortening_services,url)\n    if match:\n        return 1\n    else:\n        return -1\n\n# Example usage\nurl1 = 'http://www.google.com'\nurl2 = 'https://goo.gl'\n\nprint(tinyURL(url1))\nprint(tinyURL(url2))","metadata":{"execution":{"iopub.status.busy":"2024-03-16T19:51:58.017379Z","iopub.execute_input":"2024-03-16T19:51:58.017746Z","iopub.status.idle":"2024-03-16T19:51:58.031082Z","shell.execute_reply.started":"2024-03-16T19:51:58.017718Z","shell.execute_reply":"2024-03-16T19:51:58.029568Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"-1\n1\n","output_type":"stream"}]},{"cell_type":"code","source":"# Checking for Prefix or Suffix Separated by (-) in the Domain (Prefix/Suffix)\ndef prefixSuffix(url):\n    if '-' in urlparse(url).netloc:\n        return 1            # phishing\n    else:\n        return -1            # legitimate\n    \n# Example usage\nurl1 = 'http://www.google.com'\nurl2 = 'http://www.go-ogle.com'\n\nprint(prefixSuffix(url1))\nprint(prefixSuffix(url2))","metadata":{"execution":{"iopub.status.busy":"2024-03-16T19:52:06.901222Z","iopub.execute_input":"2024-03-16T19:52:06.901659Z","iopub.status.idle":"2024-03-16T19:52:06.909287Z","shell.execute_reply.started":"2024-03-16T19:52:06.901627Z","shell.execute_reply":"2024-03-16T19:52:06.908211Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"-1\n1\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install python-whois","metadata":{"execution":{"iopub.status.busy":"2024-03-16T20:05:30.086764Z","iopub.execute_input":"2024-03-16T20:05:30.087359Z","iopub.status.idle":"2024-03-16T20:05:49.488689Z","shell.execute_reply.started":"2024-03-16T20:05:30.087313Z","shell.execute_reply":"2024-03-16T20:05:49.487445Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Collecting python-whois\n  Downloading python-whois-0.8.0.tar.gz (109 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.6/109.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: future in /opt/conda/lib/python3.10/site-packages (from python-whois) (1.0.0)\nBuilding wheels for collected packages: python-whois\n  Building wheel for python-whois (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for python-whois: filename=python_whois-0.8.0-py3-none-any.whl size=103246 sha256=c13dfc7dbf5ab2c78d7fee13a051e1951f2f9456dc27b8ed13610723a034474e\n  Stored in directory: /root/.cache/pip/wheels/10/f1/87/145023b9a206e2e948be6480c61ef3fd3dbb81ef11b6977782\nSuccessfully built python-whois\nInstalling collected packages: python-whois\nSuccessfully installed python-whois-0.8.0\n","output_type":"stream"}]},{"cell_type":"code","source":"# importing required packages for this section\nimport whois\nfrom datetime import datetime","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import requests\n# from bs4 import BeautifulSoup\n\n# def get_website_traffic(url):\n#     try:\n#         response = requests.get(url)\n#         if response.status_code == 200:\n#             soup = BeautifulSoup(response.text, 'html.parser')\n#             # Example: Extracting Alexa Rank\n#             alexa_rank_element = soup.find('div', class_='rankmini-rank')\n#             if alexa_rank_element:\n#                 alexa_rank = alexa_rank_element.text.strip()\n#                 return alexa_rank\n#             else:\n#                 return \"Alexa rank not found\"\n#         else:\n#             return \"Failed to fetch URL, status code: \" + str(response.status_code)\n#     except Exception as e:\n#         return \"Error occurred: \" + str(e)\n\n# # Example usage:\n# url = \"https://google.com\"\n# traffic_data = get_website_traffic(url)\n# print(\"Website traffic data:\", traffic_data)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T20:43:05.360417Z","iopub.execute_input":"2024-03-16T20:43:05.360888Z","iopub.status.idle":"2024-03-16T20:43:05.368431Z","shell.execute_reply.started":"2024-03-16T20:43:05.360854Z","shell.execute_reply":"2024-03-16T20:43:05.366564Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"# import urllib.parse\n# import urllib.request\n# from bs4 import BeautifulSoup\n\n# # 12.Web traffic (Web_Traffic)\n# def web_traffic(url):\n#     try:\n#     #Filling the whitespaces in the URL if any\n#         url = urllib.parse.quote(url)\n#         rank = BeautifulSoup(urllib.request.urlopen(\"http://data.alexa.com/data?cli=10&dat=s&url=\" + url).read(), \"xml\").find(\"REACH\")['RANK']\n#         rank = int(rank)\n#     except TypeError:\n#         return 1\n#     if rank <100000:\n#         return 1       #phishing\n#     else:\n#         return 0       #legitimate\n\n# # Example usage\n# # url1 = 'http://www.google.com'\n# url1 = 'https://www.alex.com'\n# # url2 = 'http://www.go-ogle.com'\n\n# print(web_traffic(url1))\n# # print(web_traffic(url2))","metadata":{"execution":{"iopub.status.busy":"2024-03-16T20:42:55.724785Z","iopub.execute_input":"2024-03-16T20:42:55.72527Z","iopub.status.idle":"2024-03-16T20:42:55.731999Z","shell.execute_reply.started":"2024-03-16T20:42:55.725235Z","shell.execute_reply":"2024-03-16T20:42:55.730407Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"# Domain of the URL (Domain)\ndef getDomain(url):  \n    domain = urlparse(url).netloc\n    if re.match(r\"^www.\",domain):\n        domain = domain.replace(\"www.\",\"\")\n    return domain\n\n# Survival time of domain: The difference between termination time and creation time (Domain_Age)  \ndef domainAge(url):\n    domain_name = getDomain(url)\n    domain_info = whois.whois(domain_name)\n    creation_date = domain_info.creation_date\n    expiration_date = domain_info.expiration_date\n    if (isinstance(creation_date,str) or isinstance(expiration_date,str)):\n        try:\n            creation_date = datetime.strptime(creation_date,'%Y-%m-%d')\n            expiration_date = datetime.strptime(expiration_date,\"%Y-%m-%d\")\n        except:\n            return 1\n    if ((expiration_date is None) or (creation_date is None)):\n        return 1\n    elif ((type(expiration_date) is list) or (type(creation_date) is list)):\n        return 1\n    else:\n        ageofdomain = abs((expiration_date - creation_date).days)\n        if ((ageofdomain/30) < 6):\n            age = 1   #phishing\n        else:\n            age = 0   #legitimate\n    return age\n\nurl1 = \"http://www.google.com\"\nurl2 = \"http://www.facehook.com\"\n\nprint(domainAge(url1))\nprint(domainAge(url2))","metadata":{"execution":{"iopub.status.busy":"2024-03-16T20:21:36.171131Z","iopub.execute_input":"2024-03-16T20:21:36.171631Z","iopub.status.idle":"2024-03-16T20:21:37.000803Z","shell.execute_reply.started":"2024-03-16T20:21:36.171587Z","shell.execute_reply":"2024-03-16T20:21:36.999412Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"1\n0\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply the feature extraction functions to the URL column of the filtered data\nfiltered_data.loc[:,'embedded_domain'] = filtered_data.loc[:,'url'].apply(embedded_domain)\nfiltered_data.loc[:,'having_ip_address'] = filtered_data.loc[:,'url'].apply(having_ip_address)\nfiltered_data.loc[:,'no_of_dots'] = filtered_data.loc[:,'url'].apply(no_of_dots)\nfiltered_data.loc[:,'lexical_features'] = filtered_data.loc[:,'url'].apply(extract_lexical_features)\nfiltered_data.loc[:,'no_of_sensitive_words'] = filtered_data.loc[:,'url'].apply(no_of_sensitive_words)\nfiltered_data.loc[:,'out_of_position_tld'] = filtered_data.loc[:,'url'].apply(out_of_position_tld)\nfiltered_data.loc[:,'https_token'] = filtered_data.loc[:,'url'].apply(https_token)\nfiltered_data.loc[:,'url_length'] = filtered_data.loc[:,'url'].apply(url_length)\nfiltered_data.loc[:,'tinyURL'] = filtered_data.loc[:,'url'].apply(tinyURL)\nfiltered_data.loc[:,'prefixSuffix'] = filtered_data.loc[:,'url'].apply(prefixSuffix)\nfiltered_data.loc[:,'domain_age'] = filtered_data.loc[:,'url'].apply(domainAge)\n\nfiltered_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}