{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8108499,"sourceType":"datasetVersion","datasetId":4789542}],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/shag2003/knn-algorithms?scriptVersionId=172545574\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-14T17:13:43.825373Z","iopub.execute_input":"2024-04-14T17:13:43.825981Z","iopub.status.idle":"2024-04-14T17:13:43.83426Z","shell.execute_reply.started":"2024-04-14T17:13:43.825939Z","shell.execute_reply":"2024-04-14T17:13:43.832993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = pd.read_csv('/kaggle/input/phishing-urls/Preprocessed_data.csv')\nX = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, -1].values","metadata":{"execution":{"iopub.status.busy":"2024-04-14T17:13:47.661995Z","iopub.execute_input":"2024-04-14T17:13:47.662705Z","iopub.status.idle":"2024-04-14T17:13:47.715341Z","shell.execute_reply.started":"2024-04-14T17:13:47.662668Z","shell.execute_reply":"2024-04-14T17:13:47.714253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-14T17:13:49.113487Z","iopub.execute_input":"2024-04-14T17:13:49.113901Z","iopub.status.idle":"2024-04-14T17:13:49.149008Z","shell.execute_reply.started":"2024-04-14T17:13:49.11387Z","shell.execute_reply":"2024-04-14T17:13:49.147705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Splitting the dataset into the Training set and Test set","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T17:13:55.032294Z","iopub.execute_input":"2024-04-14T17:13:55.033045Z","iopub.status.idle":"2024-04-14T17:13:55.569243Z","shell.execute_reply.started":"2024-04-14T17:13:55.032998Z","shell.execute_reply":"2024-04-14T17:13:55.568226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T17:13:56.749043Z","iopub.execute_input":"2024-04-14T17:13:56.749685Z","iopub.status.idle":"2024-04-14T17:13:56.755959Z","shell.execute_reply.started":"2024-04-14T17:13:56.749654Z","shell.execute_reply":"2024-04-14T17:13:56.755077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(y_train)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T17:13:58.716688Z","iopub.execute_input":"2024-04-14T17:13:58.71708Z","iopub.status.idle":"2024-04-14T17:13:58.724132Z","shell.execute_reply.started":"2024-04-14T17:13:58.717052Z","shell.execute_reply":"2024-04-14T17:13:58.72286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T17:13:59.230268Z","iopub.execute_input":"2024-04-14T17:13:59.23067Z","iopub.status.idle":"2024-04-14T17:13:59.237865Z","shell.execute_reply.started":"2024-04-14T17:13:59.230638Z","shell.execute_reply":"2024-04-14T17:13:59.236436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(y_test)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T17:14:01.175169Z","iopub.execute_input":"2024-04-14T17:14:01.175566Z","iopub.status.idle":"2024-04-14T17:14:01.18205Z","shell.execute_reply.started":"2024-04-14T17:14:01.175535Z","shell.execute_reply":"2024-04-14T17:14:01.180711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Scaling","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test) #avoid data leakage","metadata":{"execution":{"iopub.status.busy":"2024-04-14T17:14:02.208542Z","iopub.execute_input":"2024-04-14T17:14:02.208952Z","iopub.status.idle":"2024-04-14T17:14:02.221894Z","shell.execute_reply.started":"2024-04-14T17:14:02.208923Z","shell.execute_reply":"2024-04-14T17:14:02.220639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T17:14:03.629524Z","iopub.execute_input":"2024-04-14T17:14:03.630315Z","iopub.status.idle":"2024-04-14T17:14:03.637298Z","shell.execute_reply.started":"2024-04-14T17:14:03.63028Z","shell.execute_reply":"2024-04-14T17:14:03.636084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_test.dtype)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T17:14:04.139459Z","iopub.execute_input":"2024-04-14T17:14:04.140059Z","iopub.status.idle":"2024-04-14T17:14:04.145508Z","shell.execute_reply.started":"2024-04-14T17:14:04.140019Z","shell.execute_reply":"2024-04-14T17:14:04.144322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training the kNN model on the Training set","metadata":{}},{"cell_type":"code","source":"from math import sqrt\nclass KNN():\n  def __init__(self,k):\n    self.k=k\n    print(self.k)\n  def fit(self,X_train,y_train):\n    self.x_train=X_train\n    self.y_train=y_train\n  def calculate_euclidean(self,sample1,sample2):\n    distance=0.0\n    for i in range(len(sample1)):\n      distance+=(sample1[i]-sample2[i])**2 #Euclidean Distance = sqrt(sum i to N (x1_i â€“ x2_i)^2)\n    return sqrt(distance)\n  def nearest_neighbors(self,test_sample):\n    distances=[]#calculate distances from a test sample to every sample in a training set\n    for i in range(len(self.x_train)):\n      distances.append((self.y_train[i],self.calculate_euclidean(self.x_train[i],test_sample)))\n    distances.sort(key=lambda x:x[1])#sort in ascending order, based on a distance value\n    neighbors=[]\n    for i in range(self.k): #get first k samples\n      neighbors.append(distances[i][0])\n    return neighbors\n  def predict(self,test_set):\n    predictions=[]\n    for test_sample in test_set:\n      neighbors=self.nearest_neighbors(test_sample)\n      labels=[sample for sample in neighbors]\n      prediction=max(labels,key=labels.count)\n      predictions.append(prediction)\n    return predictions","metadata":{"execution":{"iopub.status.busy":"2024-04-14T17:14:06.599765Z","iopub.execute_input":"2024-04-14T17:14:06.600342Z","iopub.status.idle":"2024-04-14T17:14:06.614848Z","shell.execute_reply.started":"2024-04-14T17:14:06.600306Z","shell.execute_reply":"2024-04-14T17:14:06.613371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=KNN(5) #our model\nmodel.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T17:14:08.028324Z","iopub.execute_input":"2024-04-14T17:14:08.028905Z","iopub.status.idle":"2024-04-14T17:14:08.035175Z","shell.execute_reply.started":"2024-04-14T17:14:08.028865Z","shell.execute_reply":"2024-04-14T17:14:08.034032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nclassifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)#The default metric is minkowski, and with p=2 is equivalent to the standard Euclidean metric.\nclassifier.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T17:14:09.372945Z","iopub.execute_input":"2024-04-14T17:14:09.373338Z","iopub.status.idle":"2024-04-14T17:14:09.554703Z","shell.execute_reply.started":"2024-04-14T17:14:09.373309Z","shell.execute_reply":"2024-04-14T17:14:09.553843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predicting the Test set results","metadata":{}},{"cell_type":"code","source":"y_pred = classifier.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T17:39:39.608208Z","iopub.execute_input":"2024-04-14T17:39:39.608783Z","iopub.status.idle":"2024-04-14T17:39:39.867254Z","shell.execute_reply.started":"2024-04-14T17:39:39.608746Z","shell.execute_reply":"2024-04-14T17:39:39.865317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions=model.predict(X_test) # our model's predictions","metadata":{"execution":{"iopub.status.busy":"2024-04-14T17:40:57.186209Z","iopub.execute_input":"2024-04-14T17:40:57.186944Z","iopub.status.idle":"2024-04-14T17:40:57.193815Z","shell.execute_reply.started":"2024-04-14T17:40:57.186906Z","shell.execute_reply":"2024-04-14T17:40:57.192138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Making the Confusion Matrix to compare both models","metadata":{"execution":{"iopub.status.busy":"2024-04-14T17:40:10.664681Z","iopub.status.idle":"2024-04-14T17:40:10.665512Z","shell.execute_reply.started":"2024-04-14T17:40:10.665251Z","shell.execute_reply":"2024-04-14T17:40:10.665277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T17:23:42.894326Z","iopub.execute_input":"2024-04-14T17:23:42.894813Z","iopub.status.idle":"2024-04-14T17:23:42.940249Z","shell.execute_reply.started":"2024-04-14T17:23:42.894775Z","shell.execute_reply":"2024-04-14T17:23:42.939147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, predictions)\nprint(cm)\naccuracy_score(y_test, predictions)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T17:23:42.942563Z","iopub.execute_input":"2024-04-14T17:23:42.943481Z","iopub.status.idle":"2024-04-14T17:23:42.988792Z","shell.execute_reply.started":"2024-04-14T17:23:42.943436Z","shell.execute_reply":"2024-04-14T17:23:42.987015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Adaptive KNN","metadata":{"execution":{"iopub.status.busy":"2024-04-14T17:40:45.206532Z","iopub.status.idle":"2024-04-14T17:40:45.207714Z","shell.execute_reply.started":"2024-04-14T17:40:45.207424Z","shell.execute_reply":"2024-04-14T17:40:45.207454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import numpy as np\nfrom collections import Counter\n\nclass AdaptiveKNN:\n    def __init__(self, k_values):\n        self.k_values = k_values\n    \n    def fit(self, X_train, y_train):\n        self.X_train = X_train\n        self.y_train = y_train\n    \n    def predict(self, X_test):\n        y_pred = []\n        for x in X_test:\n            distances = np.linalg.norm(self.X_train - x, axis=1)\n            nearest_neighbor_indices = np.argsort(distances)[:max(self.k_values)]\n            k_values_for_point = [self.k_values[idx] for idx in nearest_neighbor_indices]\n            selected_k = Counter(k_values_for_point).most_common(1)[0][0]\n            nearest_neighbor_labels = [self.y_train[idx] for idx in nearest_neighbor_indices[:selected_k]]\n            prediction = Counter(nearest_neighbor_labels).most_common(1)[0][0]\n            y_pred.append(prediction)\n        return y_pred\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T17:41:12.278333Z","iopub.execute_input":"2024-04-14T17:41:12.27878Z","iopub.status.idle":"2024-04-14T17:41:12.290046Z","shell.execute_reply.started":"2024-04-14T17:41:12.278749Z","shell.execute_reply":"2024-04-14T17:41:12.288517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Usage example:\naknn = AdaptiveKNN(k_values=[3, 5, 7])  # Define different k values\naknn.fit(X_train, y_train)  # Train the model\naKNN_pred = aknn.predict(X_test)  # Make predictions","metadata":{"execution":{"iopub.status.busy":"2024-04-14T17:41:14.582577Z","iopub.execute_input":"2024-04-14T17:41:14.583021Z","iopub.status.idle":"2024-04-14T17:41:14.681994Z","shell.execute_reply.started":"2024-04-14T17:41:14.582992Z","shell.execute_reply":"2024-04-14T17:41:14.679481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, aKNN_pred)\nprint(cm)\naccuracy_score(y_test, aKNN_pred)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T17:55:45.941042Z","iopub.execute_input":"2024-04-14T17:55:45.941558Z","iopub.status.idle":"2024-04-14T17:55:45.94793Z","shell.execute_reply.started":"2024-04-14T17:55:45.941526Z","shell.execute_reply":"2024-04-14T17:55:45.946393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Fuzzy KNN","metadata":{"execution":{"iopub.status.busy":"2024-04-14T17:41:18.983178Z","iopub.execute_input":"2024-04-14T17:41:18.983579Z","iopub.status.idle":"2024-04-14T17:41:18.988862Z","shell.execute_reply.started":"2024-04-14T17:41:18.983549Z","shell.execute_reply":"2024-04-14T17:41:18.987419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class FuzzyKNN:\n    def __init__(self, k):\n        self.k = k\n    \n    def fit(self, X_train, y_train):\n        self.X_train = X_train\n        self.y_train = y_train\n    \n    def predict(self, X_test):\n        y_pred = []\n        for x in X_test:\n            distances = np.linalg.norm(self.X_train - x, axis=1)\n            nearest_neighbor_indices = np.argsort(distances)[:self.k]\n            nearest_neighbor_labels = [self.y_train[idx] for idx in nearest_neighbor_indices]\n            membership_values = [1 / d for d in distances[nearest_neighbor_indices]]\n            label_counts = {}\n            for label, membership in zip(nearest_neighbor_labels, membership_values):\n                if label in label_counts:\n                    label_counts[label] += membership\n                else:\n                    label_counts[label] = membership\n            prediction = max(label_counts, key=label_counts.get)\n            y_pred.append(prediction)\n        return y_pred\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T17:41:19.496263Z","iopub.execute_input":"2024-04-14T17:41:19.496692Z","iopub.status.idle":"2024-04-14T17:41:19.507234Z","shell.execute_reply.started":"2024-04-14T17:41:19.496654Z","shell.execute_reply":"2024-04-14T17:41:19.505639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Usage example:\nfknn = FuzzyKNN(k=5)  # Define the number of nearest neighbors (k)\nfknn.fit(X_train, y_train)  # Train the model\nFuzzy_pred = fknn.predict(X_test)  # Make predictions","metadata":{"execution":{"iopub.status.busy":"2024-04-14T17:41:20.7692Z","iopub.execute_input":"2024-04-14T17:41:20.769653Z","iopub.status.idle":"2024-04-14T17:41:25.732697Z","shell.execute_reply.started":"2024-04-14T17:41:20.769604Z","shell.execute_reply":"2024-04-14T17:41:25.731674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, Fuzzy_pred)\nprint(cm)\naccuracy_score(y_test, Fuzzy_pred)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T17:41:27.588281Z","iopub.execute_input":"2024-04-14T17:41:27.588685Z","iopub.status.idle":"2024-04-14T17:41:27.633185Z","shell.execute_reply.started":"2024-04-14T17:41:27.588655Z","shell.execute_reply":"2024-04-14T17:41:27.63203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Weighted KNN","metadata":{"execution":{"iopub.status.busy":"2024-04-14T17:41:30.46488Z","iopub.execute_input":"2024-04-14T17:41:30.465316Z","iopub.status.idle":"2024-04-14T17:41:30.470006Z","shell.execute_reply.started":"2024-04-14T17:41:30.465281Z","shell.execute_reply":"2024-04-14T17:41:30.469059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class WeightAdjustedKNN:\n    def __init__(self, k):\n        self.k = k\n    \n    def fit(self, X_train, y_train):\n        self.X_train = X_train\n        self.y_train = y_train\n    \n    def _kernel_function(self, distances):\n        # Example kernel function: inverse distance\n        return 1 / (distances + 1e-5)\n    \n    def predict(self, X_test):\n        y_pred = []\n        for x in X_test:\n            distances = np.linalg.norm(self.X_train - x, axis=1)\n            weights = self._kernel_function(distances)\n            nearest_neighbor_indices = np.argsort(distances)[:self.k]\n            nearest_neighbor_labels = [self.y_train[idx] for idx in nearest_neighbor_indices]\n            label_weights = {}\n            for label, weight in zip(nearest_neighbor_labels, weights):\n                if label in label_weights:\n                    label_weights[label] += weight\n                else:\n                    label_weights[label] = weight\n            prediction = max(label_weights, key=label_weights.get)\n            y_pred.append(prediction)\n        return y_pred\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T17:41:31.071505Z","iopub.execute_input":"2024-04-14T17:41:31.07217Z","iopub.status.idle":"2024-04-14T17:41:31.081854Z","shell.execute_reply.started":"2024-04-14T17:41:31.072135Z","shell.execute_reply":"2024-04-14T17:41:31.080927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Usage example:\nwknn = WeightAdjustedKNN(k=5)  # Define the number of nearest neighbors (k)\nwknn.fit(X_train, y_train)  # Train the model\nwKNN_pred = wknn.predict(X_test)  # Make predictions","metadata":{"execution":{"iopub.status.busy":"2024-04-14T17:46:16.293215Z","iopub.execute_input":"2024-04-14T17:46:16.293671Z","iopub.status.idle":"2024-04-14T17:46:21.977143Z","shell.execute_reply.started":"2024-04-14T17:46:16.29364Z","shell.execute_reply":"2024-04-14T17:46:21.975136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, wKNN_pred)\nprint(cm)\naccuracy_score(y_test, wKNN_pred)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T17:46:24.275933Z","iopub.execute_input":"2024-04-14T17:46:24.276522Z","iopub.status.idle":"2024-04-14T17:46:24.32565Z","shell.execute_reply.started":"2024-04-14T17:46:24.276477Z","shell.execute_reply":"2024-04-14T17:46:24.324419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Hassanat distance KNN","metadata":{"execution":{"iopub.status.busy":"2024-04-14T17:46:27.448571Z","iopub.execute_input":"2024-04-14T17:46:27.449206Z","iopub.status.idle":"2024-04-14T17:46:27.453132Z","shell.execute_reply.started":"2024-04-14T17:46:27.449173Z","shell.execute_reply":"2024-04-14T17:46:27.452265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class HassanatDistanceKNN:\n    def __init__(self, k):\n        self.k = k\n    \n    def fit(self, X_train, y_train):\n        self.X_train = X_train\n        self.y_train = y_train\n    \n    def _hassanat_distance(self, x1, x2):\n        # Define Hassanat distance metric (example implementation)\n        max_vector = np.maximum(x1, x2)\n        min_vector = np.minimum(x1, x2)\n        return np.linalg.norm(max_vector - min_vector)\n    \n    def predict(self, X_test):\n        y_pred = []\n        for x in X_test:\n            distances = [self._hassanat_distance(x, x_train) for x_train in self.X_train]\n            nearest_neighbor_indices = np.argsort(distances)[:self.k]\n            nearest_neighbor_labels = [self.y_train[idx] for idx in nearest_neighbor_indices]\n            prediction = max(set(nearest_neighbor_labels), key=nearest_neighbor_labels.count)\n            y_pred.append(prediction)\n        return y_pred\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T17:46:28.16538Z","iopub.execute_input":"2024-04-14T17:46:28.16607Z","iopub.status.idle":"2024-04-14T17:46:28.176315Z","shell.execute_reply.started":"2024-04-14T17:46:28.166035Z","shell.execute_reply":"2024-04-14T17:46:28.175323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Usage example:\nhknn = HassanatDistanceKNN(k=5)  # Define the number of nearest neighbors (k)\nhknn.fit(X_train, y_train)  # Train the model\nhKNN_pred = hknn.predict(X_test)  # Make predictions","metadata":{"execution":{"iopub.status.busy":"2024-04-14T17:46:29.290766Z","iopub.execute_input":"2024-04-14T17:46:29.291422Z","iopub.status.idle":"2024-04-14T17:50:21.086792Z","shell.execute_reply.started":"2024-04-14T17:46:29.291386Z","shell.execute_reply":"2024-04-14T17:50:21.08544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, hKNN_pred)\nprint(cm)\naccuracy_score(y_test, hKNN_pred)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T17:50:21.089258Z","iopub.execute_input":"2024-04-14T17:50:21.089786Z","iopub.status.idle":"2024-04-14T17:50:21.134492Z","shell.execute_reply.started":"2024-04-14T17:50:21.089745Z","shell.execute_reply":"2024-04-14T17:50:21.133216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Mutual KNN","metadata":{"execution":{"iopub.status.busy":"2024-04-14T17:50:21.135851Z","iopub.execute_input":"2024-04-14T17:50:21.136212Z","iopub.status.idle":"2024-04-14T17:50:21.141268Z","shell.execute_reply.started":"2024-04-14T17:50:21.136182Z","shell.execute_reply":"2024-04-14T17:50:21.140073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MutualKNN:\n    def __init__(self, k):\n        self.k = k\n    \n    def fit(self, X_train, y_train):\n        self.X_train = X_train\n        self.y_train = y_train\n    \n    def _mutual_neighbors(self, distances):\n        mutual_neighbors = []\n        for i in range(len(distances)):\n            mutual_indices = np.where(distances[i] <= self.k)[0]\n            mutual_neighbors.append(mutual_indices)\n        return mutual_neighbors\n    \n    def predict(self, X_test):\n        y_pred = []\n        for x in X_test:\n            distances = np.linalg.norm(self.X_train - x, axis=1)\n            mutual_neighbors = self._mutual_neighbors(distances)\n            mutual_neighbor_labels = [self.y_train[idx] for idx in mutual_neighbors]\n            prediction = max(set(mutual_neighbor_labels), key=mutual_neighbor_labels.count)\n            y_pred.append(prediction)\n        return y_pred\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T17:55:57.302723Z","iopub.execute_input":"2024-04-14T17:55:57.303418Z","iopub.status.idle":"2024-04-14T17:55:57.314379Z","shell.execute_reply.started":"2024-04-14T17:55:57.303383Z","shell.execute_reply":"2024-04-14T17:55:57.312961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Usage example:\nmknn = MutualKNN(k=5)  # Define the number of nearest neighbors (k)\nmknn.fit(X_train, y_train)  # Train the model\nmKNN_pred = mknn.predict(X_test)  # Make predictions","metadata":{"execution":{"iopub.status.busy":"2024-04-14T17:56:00.883482Z","iopub.execute_input":"2024-04-14T17:56:00.884246Z","iopub.status.idle":"2024-04-14T17:56:00.999772Z","shell.execute_reply.started":"2024-04-14T17:56:00.884207Z","shell.execute_reply":"2024-04-14T17:56:00.99815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, mKNN_pred)\nprint(cm)\naccuracy_score(y_test, mKNN_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Ensemble KNN","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class EnsembleApproachKNN:\n    def __init__(self, k_max):\n        self.k_max = k_max\n    \n    def fit(self, X_train, y_train):\n        self.X_train = X_train\n        self.y_train = y_train\n    \n    def _inverse_logarithm(self, k):\n        return 1 / np.log(k + 1)\n    \n    def predict(self, X_test):\n        y_pred = []\n        for x in X_test:\n            all_distances = np.linalg.norm(self.X_train - x, axis=1)\n            sorted_indices = np.argsort(all_distances)\n            k_values = np.arange(1, self.k_max + 1, 2)\n            weights = [self._inverse_logarithm(k) for k in k_values]\n            label_counts = {}\n            for k, weight in zip(k_values, weights):\n                nearest_neighbor_indices = sorted_indices[:k]\n                nearest_neighbor_labels = [self.y_train[idx] for idx in nearest_neighbor_indices]\n                for label in nearest_neighbor_labels:\n                    if label in label_counts:\n                        label_counts[label] += weight\n                    else:\n                        label_counts[label] = weight\n            prediction = max(label_counts, key=label_counts.get)\n            y_pred.append(prediction)\n        return y_pred","metadata":{"execution":{"iopub.status.busy":"2024-04-14T17:56:07.229541Z","iopub.execute_input":"2024-04-14T17:56:07.23004Z","iopub.status.idle":"2024-04-14T17:56:07.245088Z","shell.execute_reply.started":"2024-04-14T17:56:07.230004Z","shell.execute_reply":"2024-04-14T17:56:07.243223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Usage example:\neaknn = EnsembleApproachKNN(k_max=10)  # Define the maximum value of k\neaknn.fit(X_train, y_train)  # Train the model\nEKNN_pred = eaknn.predict(X_test)  # Make predictions","metadata":{"execution":{"iopub.status.busy":"2024-04-14T17:56:10.146231Z","iopub.execute_input":"2024-04-14T17:56:10.14667Z","iopub.status.idle":"2024-04-14T17:56:15.288216Z","shell.execute_reply.started":"2024-04-14T17:56:10.146637Z","shell.execute_reply":"2024-04-14T17:56:15.287031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, EKNN_pred)\nprint(cm)\naccuracy_score(y_test, EKNN_pred)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T17:56:15.749252Z","iopub.execute_input":"2024-04-14T17:56:15.749695Z","iopub.status.idle":"2024-04-14T17:56:15.794318Z","shell.execute_reply.started":"2024-04-14T17:56:15.749656Z","shell.execute_reply":"2024-04-14T17:56:15.793212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Locally adaptive KNN with Discrimination class (LA-KNN):","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class LocallyAdaptiveKNN:\n#     def __init__(self, k):\n#         self.k = k\n    \n#     def fit(self, X_train, y_train):\n#         self.X_train = X_train\n#         self.y_train = y_train\n    \n#     def _calculate_discrimination_classes(self, X_train, y_train):\n#         # Define discrimination classes based on majority and second majority class neighbors\n#         # This is a simplified example, actual implementation may vary\n#         discrimination_classes = []\n#         for i in range(len(X_train)):\n#             distances = np.linalg.norm(X_train - X_train[i], axis=1)\n#             sorted_indices = np.argsort(distances)\n#             k_nearest_labels = [y_train[idx] for idx in sorted_indices[1:self.k + 1]]  # Exclude itself\n#             majority_class = max(set(k_nearest_labels), key=k_nearest_labels.count)\n#             second_majority_class = sorted(set(k_nearest_labels), key=k_nearest_labels.count)[-2]\n#             discrimination_classes.append((majority_class, second_majority_class))\n#         return discrimination_classes\n    \n#     def _calculate_optimal_k_values(self, discrimination_classes):\n#         # Define optimal k values based on discrimination classes\n#         # This is a simplified example, actual implementation may vary\n#         optimal_k_values = []\n#         for majority_class, second_majority_class in discrimination_classes:\n#             if majority_class == second_majority_class:\n#                 optimal_k_values.append(self.k)\n#             else:\n#                 # Define your own rules to determine optimal k value\n#                 optimal_k_values.append(self.k // 2)  # Example: use half of k\n#         return optimal_k_values\n    \n#     def predict(self, X_test):\n#         y_pred = []\n#         discrimination_classes = self._calculate_discrimination_classes(self.X_train, self.y_train)\n#         optimal_k_values = self._calculate_optimal_k_values(discrimination_classes)\n#         for x, k in zip(X_test, optimal_k_values):\n#             distances = np.linalg.norm(self.X_train - x, axis=1)\n#             sorted_indices = np.argsort(distances)\n#             nearest_neighbor_indices = sorted_indices[:k]\n#             nearest_neighbor_labels = [self.y_train[idx] for idx in nearest_neighbor_indices]\n#             prediction = max(set(nearest_neighbor_labels), key=nearest_neighbor_labels.count)\n#             y_pred.append(prediction)\n#         return y_pred\n\n# # Usage example:\n# # laknn = LocallyAdaptiveKNN(k=5)  # Define the number of nearest neighbors (k)\n# # laknn.fit(X_train, y_train)  # Train the model\n# # y_pred = laknn.predict(X_test)  # Make predictions\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Generalised mean distance KNN (GMD-KNN):","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import numpy as np\n\n# class GeneralisedMeanDistanceKNN:\n#     def __init__(self, k):\n#         self.k = k\n    \n#     def fit(self, X_train, y_train):\n#         self.X_train = X_train\n#         self.y_train = y_train\n    \n#     def _compute_distance(self, x1, x2):\n#         return np.linalg.norm(x1 - x2)\n    \n#     def _compute_mean_distance(self, X_train, y_train, x, k):\n#         class_distances = {}\n#         for label in set(y_train):\n#             label_indices = np.where(y_train == label)[0]\n#             distances = [self._compute_distance(x, X_train[idx]) for idx in label_indices]\n#             sorted_distances = sorted(distances)[:k]\n#             class_distances[label] = np.mean(sorted_distances)\n#         return class_distances\n    \n#     def predict(self, X_test):\n#         y_pred = []\n#         for x in X_test:\n#             mean_distances = self._compute_mean_distance(self.X_train, self.y_train, x, self.k)\n#             prediction = min(mean_distances, key=mean_distances.get)\n#             y_pred.append(prediction)\n#         return y_pred\n\n# # Usage example:\n# # gmdknn = GeneralisedMeanDistanceKNN(k=5)  # Define the number of nearest neighbors (k)\n# # gmdknn.fit(X_train, y_train)  # Train the model\n# # y_pred = gmdknn.predict(X_test)  # Make predictions\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Ensemble approach KNN (EA-KNN):","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import numpy as np\n\n# class EnsembleApproachKNN:\n#     def __init__(self, k_max):\n#         self.k_max = k_max\n    \n#     def fit(self, X_train, y_train):\n#         self.X_train = X_train\n#         self.y_train = y_train\n    \n#     def _weight_summation(self, distances, k_values):\n#         weights = [1 / np.log(k + 1) for k in range(1, self.k_max + 1, 2)]\n#         weighted_sum = 0\n#         for k, distance in zip(k_values, distances):\n#             if k <= self.k_max:\n#                 weighted_sum += weights[(k-1) // 2] * distance\n#         return weighted_sum\n    \n#     def predict(self, X_test):\n#         y_pred = []\n#         for x in X_test:\n#             distances = np.linalg.norm(self.X_train - x, axis=1)\n#             sorted_indices = np.argsort(distances)\n#             k_values = np.arange(1, len(self.X_train) + 1, 2)\n#             weighted_sums = [self._weight_summation(distances[sorted_indices][:k], k_values[:k]) for k in range(1, len(self.X_train) + 1)]\n#             prediction = self.y_train[sorted_indices[np.argmin(weighted_sums)]]\n#             y_pred.append(prediction)\n#         return y_pred\n\n# # Usage example:\n# # eaknn = EnsembleApproachKNN(k_max=10)  # Define the maximum value of k\n# # eaknn.fit(X_train, y_train)  # Train the model\n# # y_pred = eaknn.predict(X_test)  # Make predictions\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualising the Test set results","metadata":{}},{"cell_type":"code","source":"from matplotlib.colors import ListedColormap\nX_set, y_set = sc.inverse_transform(X_test), y_test\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 10, stop = X_set[:, 0].max() + 10, step = 1),\n                     np.arange(start = X_set[:, 1].min() - 1000, stop = X_set[:, 1].max() + 1000, step = 1))\nplt.contourf(X1, X2, classifier.predict(sc.transform(np.array([X1.ravel(), X2.ravel()]).T)).reshape(X1.shape),\n             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\nplt.xlim(X1.min(), X1.max())\nplt.ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1], c = ListedColormap(('red', 'green'))(i), label = j)\nplt.title('K-NN (Test set)')\nplt.xlabel('Age')\nplt.ylabel('Estimated Salary')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}